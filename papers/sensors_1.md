---
layout: default
title: AI for Earth Sciences
description: org
---

## Sensors and Sampling

| Start | End | Type | Speaker | Title and Info |   
| ---- | ---- | --------- | ------------- | ----------------- | 
| 6:55 | 6:58 | Intro | Johanna Hansen | Session Overview and Introduction |  
| 6:58 | 7:22 | Keynote | [Yogesh Girdhar](http://warp.whoi.edu/) | [Curious Robots for Scientific Sampling](#yogesh-girdhar) |    
| 7:22 | 7:35 | Invited Talk | [Hannah Kerner](https://hannah-rae.github.io/) |  [Eyes in the sky without boots on the ground: Using satellites and machine learning to monitor agriculture and food security during COVID-19](#hannah-kerner) |  
| 7:35 | 7:58 | Invited Talk | [Renaud Detry](http://renaud-detry.net/)  | [Autonomous robot manipulation for planetary science: Mars Sample Return & Climbing Lava Tubes](#renaud-detry) |   
| 7:58 | 8:06 | Invited Paper | [Alzayat Saleh & Issam Hadj Laradji](https://github.com/alzayats/DeepFish) | [DeepFish: A realistic fish‑habitat dataset to evaluate algorithms for underwater visual analysis](Alzayat-Saleh) |     
| 8:06 | 8:17 | Invited Paper | [Jean-Francois Tremblay](https://norlab.ulaval.ca/research/montmorencydataset) | [Automatic three‐dimensional mapping for tree diameter measurements in inventory operations](#jean-francois-tremblay) |     
| 8:17 | 8:30 | Lightning Talks |  Contributed |  |   
| 8:30 | 8:55 | Q&A | Roundtable Discussion Speakers | Live Zoom Session |   



# Sensors and Sampling
##  Yogesh Girdhar
### Scientific Sampling Robots with Curiosity
<details closed> <summary>Expand </summary>WARPLab's research focuses on both the science and systems of exploration robots in extreme, communication starved environments such as the deep sea. It aims to develop robotics and machine learning-based techniques to enable search, discovery, and mapping of natural phenomena that are difficult to observe and study due to various physical and information-theoretic challenges. 

WARPLab is headed by Yogesh Girdhar, and is part of the Deep Submergence Laboratory (DSL), and the Applied Ocean Physics & Engineering (AOPE) department at Woods Hole Oceanographic Institution.</details>

---

## Hannah Kerner
### Eyes in the sky without boots on the ground: Using satellites and machine learning to monitor agriculture and food security during COVID-19  
<details closed> <summary>Expand</summary>
Hannah Kerner is an Assistant Research Professor at the University of Maryland, College Park. Her research focuses on developing machine learning solutions for remote sensing applications in agricultural monitoring, food security, and Earth/planetary science. She is the Machine Learning Lead and U.S. Domestic Co-Lead for NASA Harvest, NASA’s food security initiative run out of the University of Maryland.
</details>

---

## Renaud Detry
### Autonomous robot manipulation for planetary science: Mars Sample Return & Climbing Lava Tubes
<details closed> <summary>Expand </summary>This talk will highlight work at NASA on robotic missions from a machine vision perspective. The discussion will focus on the science questions that NASA hopes to answer through returned samples from Mars and the challenges imposed on robotic systems used for scientific data collection. 

Renaud Detry is the group leader for the Perception Systems group at NASA's Jet Propulsion Laboratory (JPL). Detry earned his Master's and Ph.D. degrees in computer engineering and robot learning from ULiege in 2006 and 2010. He served as a postdoc at KTH and ULiege between 2011 and 2015, before joining the Robotics and Mobility Section at JPL in 2016. His research interests are perception and learning for manipulation, robot grasping, and mobility, for terrestrial and planetary applications. At JPL, Detry leads the machine-vision team of the Mars Sample Return surface mission, and he leads and contributes to a variety of research projects related to industrial robot manipulation, orbital image understanding, in-space assembly, and autonomous wheeled or legged mobility for Mars, Europa, and Enceladus. </details>

---

# Alzayat Saleh
### DeepFish: A realistic fish‑habitat dataset to evaluate algorithms for underwater visual analysis
<details closed> <summary>Expand </summary>Visual analysis of complex fish habitats is an important step towards sustainable fisheries for human consumption and environmental protection. Deep Learning methods have shown great promise for scene analysis when trained on large-scale datasets. However, current datasets for fish analysis tend to focus on the classification task within constrained, plain environments which do not capture the complexity of underwater fish habitats. To address this limitation, we present DeepFish as a benchmark suite with a large-scale dataset to train and test methods for several computer vision tasks. The dataset consists of approximately 40 thousand images collected underwater from 20 habitats in the marine-environments of tropical Australia. The dataset originally contained only classification labels. Thus, we collected point-level and segmentation labels to have a more comprehensive fish analysis benchmark. These labels enable models to learn to automatically monitor fish count, identify their locations, and estimate their sizes. Our experiments provide an in-depth analysis of the dataset characteristics, and the performance evaluation of several state-of-the-art approaches based on our benchmark. Although models pre-trained on ImageNet have successfully performed on this benchmark, there is still room for improvement. Therefore, this benchmark serves as a testbed to motivate further development in this challenging domain of underwater computer vision. </details>

## Jean-Francois Tremblay  
### Automatic three‐dimensional mapping for tree diameter measurements in inventory operations
<details closed> <summary>Expand </summary>Forestry is a major industry in many parts of the world, yet this potential domain of application area has been overlooked by the robotics community. For instance, forest inventory, a cornerstone of efficient and sustainable forestry, is still traditionally performed manually by qualified professionals. The lack of automation in this particular task, consisting chiefly of measuring tree attributes, limits its speed, and, therefore, the area that can be economically covered. To this effect, we propose to use recent advancements in three‐dimensional mapping approaches in forests to automatically measure tree diameters from mobile robot observations. While previous studies showed the potential for such technology, they lacked a rigorous analysis of diameter estimation methods in challenging and large‐scale forest environments. Here, we validated multiple diameter estimation methods, including two novel ones, in a new publicly‐available dataset which includes four different forest sites, 11 trajectories, totaling 1458 tree observations, and 14,000 m2. From our extensive validation, we concluded that our mapping method is usable in the context of automated forest inventory, with our best diameter estimation method yielding a root mean square error of 3.45 cm for our whole dataset and 2.04 cm in ideal conditions consisting of mature forest with well‐spaced trees. Furthermore, we release this dataset to the public (https://norlab.ulaval.ca/research/montmorencydataset), to spur further research in robotic forest inventories. Finally, stemming from this large‐scale experiment, we provide recommendations for future deployments of mobile robots in a forestry context.

Jean-François is a Ph.D. student at McGill’s Mobile Robotics Lab, under the supervision of prof. Dave Meger. He is interested in model-based RL for mobile robot navigation in unstructured environments such as forests, tundra or underwater.  Previously he was a masters student at the Northern Robotics Laboratory (Norlab), working on lidar mapping and perception for forestry applications.</details>
